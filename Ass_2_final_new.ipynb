{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, transforms, utils\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    "\n",
    "net_param = {'conv':[(),\n",
    "                          (3, 16, 5, 1, 0), \n",
    "                          (16, 32, 3, 1, 1),\n",
    "                          (32, 32, 3, 1, 0),\n",
    "                          (32, 16, 3, 1, 1)], # in_channels, out_channels, kernel_size, stride, padding\n",
    "              'pool':[(), \n",
    "                      (2, 2, 0),\n",
    "                      (2, 2, 0)], # kernel_size, stride, padding\n",
    "              'fc':[(), \n",
    "                    (16*6*6, 120),\n",
    "                    (120, 60), \n",
    "                    (60, 10)], # in_channels, out_channels\n",
    "              'drop':[0, \n",
    "                      0.25, \n",
    "                      0.5]\n",
    "             }\n",
    "             \n",
    "epoch = 30\n",
    "\n",
    "optimizer_param_set = {'1e-4_expo': (1e-4, 'expo'),\n",
    "                       '5e-4_expo': (5e-4, 'expo'),\n",
    "                       '1e-5_step': (1e-5, 'step'), \n",
    "                       '1e-4_step': (1e-4, 'step'), \n",
    "                       '5e-4_step': (5e-4, 'step'), \n",
    "                       '1e-4_mult': (1e-4, 'mult'),\n",
    "                       '5e-4_mult': (5e-4, 'mult')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    \n",
    "    # overall training correct rate\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloaders['train'], 0):\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Training accuracy: %.2f %%' % (100 * correct / total))\n",
    "    \n",
    "    # overall testing correct rate\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloaders['test'], 0):\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Testing accuracy: %.2f %% (%d / %d)' % ((100 * correct / total), correct, total))\n",
    "    \n",
    "    # count testing predictions for each class\n",
    "    correct_pred = {classname: 0 for classname in class_names}\n",
    "    total_pred = {classname: 0 for classname in class_names}\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloaders['test'], 0):\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction:\n",
    "                    correct_pred[class_names[label]] += 1\n",
    "                total_pred[class_names[label]] += 1\n",
    "\n",
    "    # print accuracy for each class\n",
    "    print(\"Testing accuracy (each class): \")\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(\"{:1s}: {:.1f}%;  \".format(classname, accuracy), end=' ')\n",
    "        if classname == \"5\":\n",
    "            print()\n",
    "    print()\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def train_test(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    \n",
    "    for epoch in range(num_epochs):  \n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(dataloaders['train'], 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()                \n",
    "                \n",
    "        print(datetime.datetime.now(), ' Epoch', (epoch + 1), ': Average Loss', round(running_loss / 3000, 8))\n",
    "        model.loss_.append(round(running_loss / 3000, 8))\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        '''if epoch % 5 == 4:\n",
    "            print('epoch', (epoch+1))\n",
    "            test(model)'''\n",
    "    \n",
    "    print('Finished Training')\n",
    "    \n",
    "    test(model)\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Data transformer\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((32,32)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((32,32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Dataset initialization\n",
    "data_dir = 'data' \n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'test']} # Read train and test sets, respectively.\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=0) for x in ['train', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Set device to \"cpu\" if you have no gpu\n",
    "paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Input - 1x32x32\n",
    "    Output - 10\n",
    "    CONV1->CONV2->POOL1->CONV3->CONV4->POOL2->FC1->FC2->FC3\n",
    "    \"\"\"\n",
    "    def __init__(self, params):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #Initialize layers\n",
    "        self.params = params\n",
    "        self.n_layers = len(params['conv'])+len(params['pool'])+len(params['fc'])+len(params['drop'])-4\n",
    "        self.printed = False\n",
    "        self.loss_ = []\n",
    "        \n",
    "        if self.n_layers == 11:\n",
    "            self.conv1 = nn.Conv2d(*self.params['conv'][1])\n",
    "            self.conv2 = nn.Conv2d(*self.params['conv'][2])\n",
    "            self.conv3 = nn.Conv2d(*self.params['conv'][3])\n",
    "            self.conv4 = nn.Conv2d(*self.params['conv'][4])\n",
    "            \n",
    "            self.pool1 = nn.MaxPool2d(*self.params['pool'][1])\n",
    "            self.pool2 = nn.MaxPool2d(*self.params['pool'][2])\n",
    "            \n",
    "            self.fc1 = nn.Linear(*self.params['fc'][1])\n",
    "            self.fc2 = nn.Linear(*self.params['fc'][2])\n",
    "            self.fc3 = nn.Linear(*self.params['fc'][3])\n",
    "            \n",
    "            self.dropout1 = nn.Dropout(self.params['drop'][1])\n",
    "            self.dropout2 = nn.Dropout(self.params['drop'][2])\n",
    "            \n",
    "        elif self.n_layers == 10:\n",
    "            self.conv1 = nn.Conv2d(*self.params['conv'][1])\n",
    "            self.conv2 = nn.Conv2d(*self.params['conv'][2])\n",
    "            self.conv3 = nn.Conv2d(*self.params['conv'][3])\n",
    "            \n",
    "            self.pool1 = nn.MaxPool2d(*self.params['pool'][1])\n",
    "            self.pool2 = nn.MaxPool2d(*self.params['pool'][2])\n",
    "            \n",
    "            self.fc1 = nn.Linear(*self.params['fc'][1])\n",
    "            self.fc2 = nn.Linear(*self.params['fc'][2])\n",
    "            self.fc3 = nn.Linear(*self.params['fc'][3])\n",
    "            \n",
    "            self.dropout1 = nn.Dropout(self.params['drop'][1])\n",
    "            self.dropout2 = nn.Dropout(self.params['drop'][2])\n",
    "        \n",
    "        elif self.n_layers == 9:\n",
    "            self.conv1 = nn.Conv2d(*self.params['conv'][1])\n",
    "            self.conv2 = nn.Conv2d(*self.params['conv'][2])\n",
    "            \n",
    "            self.pool1 = nn.MaxPool2d(*self.params['pool'][1])\n",
    "            self.pool2 = nn.MaxPool2d(*self.params['pool'][2])\n",
    "            \n",
    "            self.fc1 = nn.Linear(*self.params['fc'][1])\n",
    "            self.fc2 = nn.Linear(*self.params['fc'][2])\n",
    "            self.fc3 = nn.Linear(*self.params['fc'][3])\n",
    "            \n",
    "            self.dropout1 = nn.Dropout(self.params['drop'][1])\n",
    "            self.dropout2 = nn.Dropout(self.params['drop'][2])\n",
    "            \n",
    "\n",
    "    def forward(self, img):\n",
    "        # Implement forward pass\n",
    "        x = img\n",
    "        \n",
    "        if self.n_layers == 11:\n",
    "            x = F.relu(self.conv1(x))\n",
    "            if not self.printed: \n",
    "                print(\"CONV1\", x.size(), end=\" || \")\n",
    "            x = F.relu(self.conv2(x))\n",
    "            if not self.printed: \n",
    "                print(\"CONV2\", x.size(), end=\" || \")\n",
    "            x = self.pool1(x)\n",
    "            if not self.printed: \n",
    "                print(\"POOL1\", x.size())\n",
    "        \n",
    "            x = F.relu(self.conv3(x))\n",
    "            if not self.printed: \n",
    "                print(\"CONV3\", x.size(), end=\" || \")\n",
    "            x = F.relu(self.conv4(x))\n",
    "            if not self.printed: \n",
    "                print(\"CONV4\", x.size(), end=\" || \")\n",
    "            x = self.pool2(x)\n",
    "            if not self.printed: \n",
    "                print(\"POOL2\", x.size())\n",
    "        \n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            if not self.printed: \n",
    "                print(\"FC1\", x.size(), end=\" || \")\n",
    "            x = F.relu(self.fc2(x))\n",
    "            if not self.printed: \n",
    "                print(\"FC2\", x.size(), end=\" || \")\n",
    "            x = self.fc3(x)\n",
    "            if not self.printed: \n",
    "                print(\"FC3\", x.size())\n",
    "                \n",
    "        elif self.n_layers == 10:\n",
    "            x = F.relu(self.conv1(x))\n",
    "            if not self.printed: \n",
    "                print(\"CONV1\", x.size(), end=\" || \")\n",
    "            x = self.pool1(x)\n",
    "            if not self.printed: \n",
    "                print(\"POOL1\", x.size())\n",
    "        \n",
    "            x = F.relu(self.conv2(x))\n",
    "            if not self.printed: \n",
    "                print(\"CONV2\", x.size(), end=\" || \")\n",
    "            x = F.relu(self.conv3(x))\n",
    "            if not self.printed: \n",
    "                print(\"CONV3\", x.size(), end=\" || \")\n",
    "            x = self.pool2(x)\n",
    "            if not self.printed: \n",
    "                print(\"POOL2\", x.size())\n",
    "        \n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            if not self.printed: \n",
    "                print(\"FC1\", x.size(), end=\" || \")\n",
    "            x = F.relu(self.fc2(x))\n",
    "            if not self.printed: \n",
    "                print(\"FC2\", x.size(), end=\" || \")\n",
    "            x = self.fc3(x)\n",
    "            if not self.printed: \n",
    "                print(\"FC3\", x.size())\n",
    "        \n",
    "        elif self.n_layers == 9:\n",
    "            x = F.relu(self.conv1(x))\n",
    "            if not self.printed: \n",
    "                print(\"CONV1\", x.size(), end=\" || \")\n",
    "            x = self.pool1(x)\n",
    "            if not self.printed: \n",
    "                print(\"POOL1\", x.size())\n",
    "        \n",
    "            x = F.relu(self.conv2(x))\n",
    "            if not self.printed: \n",
    "                print(\"CONV2\", x.size(), end=\" || \")\n",
    "            x = self.pool2(x)\n",
    "            if not self.printed: \n",
    "                print(\"POOL2\", x.size())\n",
    "        \n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            if not self.printed: \n",
    "                print(\"FC1\", x.size(), end=\" || \")\n",
    "            x = F.relu(self.fc2(x))\n",
    "            if not self.printed: \n",
    "                print(\"FC2\", x.size(), end=\" || \")\n",
    "            x = self.fc3(x)\n",
    "            if not self.printed: \n",
    "                print(\"FC3\", x.size())\n",
    "        \n",
    "        self.printed = True\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer parameter set:  1e-4_mult\n",
      "2021-05-09 20:04:09.520563\n",
      "CONV1 torch.Size([4, 16, 28, 28]) || CONV2 torch.Size([4, 32, 28, 28]) || POOL1 torch.Size([4, 32, 14, 14])\n",
      "CONV3 torch.Size([4, 32, 12, 12]) || CONV4 torch.Size([4, 16, 12, 12]) || POOL2 torch.Size([4, 16, 6, 6])\n",
      "FC1 torch.Size([4, 120]) || FC2 torch.Size([4, 60]) || FC3 torch.Size([4, 10])\n",
      "2021-05-09 20:05:02.297021  Epoch 1 : Average Loss 3.71754031\n",
      "2021-05-09 20:05:49.278300  Epoch 2 : Average Loss 2.16361152\n",
      "2021-05-09 20:06:45.339119  Epoch 3 : Average Loss 1.74501321\n",
      "2021-05-09 20:07:44.644929  Epoch 4 : Average Loss 1.50915171\n",
      "2021-05-09 20:08:36.352695  Epoch 5 : Average Loss 1.35554418\n",
      "2021-05-09 20:09:29.163194  Epoch 6 : Average Loss 1.23776768\n",
      "2021-05-09 20:10:26.967405  Epoch 7 : Average Loss 1.15838255\n",
      "2021-05-09 20:11:23.230014  Epoch 8 : Average Loss 1.07924611\n",
      "2021-05-09 20:12:15.077418  Epoch 9 : Average Loss 1.03045697\n",
      "2021-05-09 20:13:11.975314  Epoch 10 : Average Loss 0.9792995\n",
      "2021-05-09 20:14:05.030502  Epoch 11 : Average Loss 0.92601067\n",
      "2021-05-09 20:14:54.317131  Epoch 12 : Average Loss 0.87573007\n",
      "2021-05-09 20:15:49.339951  Epoch 13 : Average Loss 0.83883118\n",
      "2021-05-09 20:16:42.998049  Epoch 14 : Average Loss 0.79260197\n",
      "2021-05-09 20:17:32.182015  Epoch 15 : Average Loss 0.7578966\n",
      "2021-05-09 20:18:25.301959  Epoch 16 : Average Loss 0.7327602\n",
      "2021-05-09 20:19:24.014648  Epoch 17 : Average Loss 0.70499695\n",
      "2021-05-09 20:20:30.356563  Epoch 18 : Average Loss 0.6717619\n",
      "2021-05-09 20:21:25.558042  Epoch 19 : Average Loss 0.64621769\n",
      "2021-05-09 20:22:16.115165  Epoch 20 : Average Loss 0.62152915\n",
      "2021-05-09 20:23:05.195402  Epoch 21 : Average Loss 0.5900129\n",
      "2021-05-09 20:23:56.179727  Epoch 22 : Average Loss 0.57143352\n",
      "2021-05-09 20:24:48.214488  Epoch 23 : Average Loss 0.55111883\n",
      "2021-05-09 20:25:36.554994  Epoch 24 : Average Loss 0.52176901\n",
      "2021-05-09 20:26:26.286177  Epoch 25 : Average Loss 0.50636255\n",
      "2021-05-09 20:27:20.060142  Epoch 26 : Average Loss 0.47877672\n",
      "2021-05-09 20:28:09.515660  Epoch 27 : Average Loss 0.46184425\n",
      "2021-05-09 20:28:57.986130  Epoch 28 : Average Loss 0.43983523\n",
      "2021-05-09 20:29:49.710458  Epoch 29 : Average Loss 0.42096141\n",
      "2021-05-09 20:30:39.777821  Epoch 30 : Average Loss 0.40494357\n",
      "Finished Training\n",
      "Training accuracy: 95.17 %\n",
      "Testing accuracy: 86.88 % (4344 / 5000)\n",
      "Testing accuracy (each class): \n",
      "0: 89.0%;   1: 89.4%;   2: 86.6%;   3: 80.6%;   4: 92.2%;   5: 84.8%;   \n",
      "6: 87.8%;   7: 88.2%;   8: 84.2%;   9: 86.0%;   \n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'1e-4expo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-3722f58ad651>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_param_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdecay_strategy\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'expo'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '1e-4expo'"
     ]
    }
   ],
   "source": [
    "loss_col = []\n",
    "for opt in ('1e-4_mult','1e-4expo','1e-4_step'):\n",
    "    model_ft = Net(net_param)\n",
    "    model_ft = model_ft.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    learning_rate, decay_strategy = optimizer_param_set[opt]\n",
    "    optimizer_ft = optim.Adam(model_ft.parameters(), lr=learning_rate)\n",
    "    if decay_strategy=='expo':\n",
    "        lr_scheduler_ft = lr_scheduler.ExponentialLR(optimizer_ft, gamma=0.2)\n",
    "    elif decay_strategy=='step':\n",
    "        lr_scheduler_ft = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.2)\n",
    "    elif decay_strategy=='mult':\n",
    "        lr_scheduler_ft = lr_scheduler.MultiStepLR(optimizer_ft, milestones=[10,25,30], gamma=0.2)\n",
    "    else:\n",
    "        print(\"ERROR 2\")\n",
    "            \n",
    "    print(\"optimizer parameter set: \", opt)\n",
    "    print(datetime.datetime.now())\n",
    "    epo = epoch\n",
    "    train_test(model_ft, criterion, optimizer_ft, lr_scheduler_ft, num_epochs=epo)\n",
    "        \n",
    "    loss_col.append(model_ft.loss_)\n",
    "    PATH = \"./cnn_chosen_\"+opt+\"_.pth\"\n",
    "    paths.append(PATH)\n",
    "    torch.save({'epoch': epoch,\n",
    "                'model_state_dict': model_ft.state_dict(),\n",
    "                'optimizer_state_dict': optimizer_ft.state_dict()\n",
    "               }, PATH)\n",
    "        \n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer parameter set:  1e-4_expo\n",
      "2021-05-09 20:53:02.613134\n",
      "CONV1 torch.Size([4, 16, 28, 28]) || CONV2 torch.Size([4, 32, 28, 28]) || POOL1 torch.Size([4, 32, 14, 14])\n",
      "CONV3 torch.Size([4, 32, 12, 12]) || CONV4 torch.Size([4, 16, 12, 12]) || POOL2 torch.Size([4, 16, 6, 6])\n",
      "FC1 torch.Size([4, 120]) || FC2 torch.Size([4, 60]) || FC3 torch.Size([4, 10])\n",
      "2021-05-09 20:53:51.070341  Epoch 1 : Average Loss 3.90760594\n",
      "2021-05-09 20:54:37.831289  Epoch 2 : Average Loss 2.25920461\n",
      "2021-05-09 20:55:25.889145  Epoch 3 : Average Loss 1.82911768\n",
      "2021-05-09 20:56:17.023429  Epoch 4 : Average Loss 1.57326537\n",
      "2021-05-09 20:57:03.012910  Epoch 5 : Average Loss 1.41169154\n",
      "2021-05-09 20:57:48.154318  Epoch 6 : Average Loss 1.30345533\n",
      "2021-05-09 20:58:37.629758  Epoch 7 : Average Loss 1.20659882\n",
      "2021-05-09 20:59:29.338506  Epoch 8 : Average Loss 1.11869972\n",
      "2021-05-09 21:00:15.387889  Epoch 9 : Average Loss 1.05078785\n",
      "2021-05-09 21:01:03.143589  Epoch 10 : Average Loss 1.00435304\n",
      "2021-05-09 21:01:55.152480  Epoch 11 : Average Loss 0.9578496\n",
      "2021-05-09 21:02:45.922449  Epoch 12 : Average Loss 0.90317768\n",
      "2021-05-09 21:03:32.686468  Epoch 13 : Average Loss 0.85957134\n",
      "2021-05-09 21:04:22.011907  Epoch 14 : Average Loss 0.8453624\n",
      "2021-05-09 21:05:17.015181  Epoch 15 : Average Loss 0.78668552\n",
      "2021-05-09 21:06:05.692950  Epoch 16 : Average Loss 0.75923061\n",
      "2021-05-09 21:06:52.303973  Epoch 17 : Average Loss 0.73625062\n",
      "2021-05-09 21:07:42.617647  Epoch 18 : Average Loss 0.70086622\n",
      "2021-05-09 21:08:36.792482  Epoch 19 : Average Loss 0.67434555\n",
      "2021-05-09 21:09:23.866604  Epoch 20 : Average Loss 0.65424164\n",
      "2021-05-09 21:10:12.012145  Epoch 21 : Average Loss 0.61831248\n",
      "2021-05-09 21:11:04.816015  Epoch 22 : Average Loss 0.59156386\n",
      "2021-05-09 21:11:55.861900  Epoch 23 : Average Loss 0.56730205\n",
      "2021-05-09 21:12:42.722234  Epoch 24 : Average Loss 0.5495713\n",
      "2021-05-09 21:13:32.497494  Epoch 25 : Average Loss 0.52777006\n",
      "2021-05-09 21:14:26.580731  Epoch 26 : Average Loss 0.5084994\n",
      "2021-05-09 21:15:19.211089  Epoch 27 : Average Loss 0.48666711\n",
      "2021-05-09 21:16:10.083291  Epoch 28 : Average Loss 0.47092158\n",
      "2021-05-09 21:17:04.376344  Epoch 29 : Average Loss 0.44005869\n",
      "2021-05-09 21:17:52.505318  Epoch 30 : Average Loss 0.42522537\n",
      "Finished Training\n",
      "Training accuracy: 95.45 %\n",
      "Testing accuracy: 86.30 % (4315 / 5000)\n",
      "Testing accuracy (each class): \n",
      "0: 88.8%;   1: 88.2%;   2: 85.8%;   3: 80.6%;   4: 89.2%;   5: 81.2%;   \n",
      "6: 86.2%;   7: 90.0%;   8: 86.0%;   9: 87.0%;   \n",
      "\n",
      "optimizer parameter set:  1e-4_step\n",
      "2021-05-09 21:18:20.930087\n",
      "CONV1 torch.Size([4, 16, 28, 28]) || CONV2 torch.Size([4, 32, 28, 28]) || POOL1 torch.Size([4, 32, 14, 14])\n",
      "CONV3 torch.Size([4, 32, 12, 12]) || CONV4 torch.Size([4, 16, 12, 12]) || POOL2 torch.Size([4, 16, 6, 6])\n",
      "FC1 torch.Size([4, 120]) || FC2 torch.Size([4, 60]) || FC3 torch.Size([4, 10])\n",
      "2021-05-09 21:19:11.785334  Epoch 1 : Average Loss 3.67644014\n",
      "2021-05-09 21:20:04.721436  Epoch 2 : Average Loss 2.17140806\n",
      "2021-05-09 21:20:51.135253  Epoch 3 : Average Loss 1.76989265\n",
      "2021-05-09 21:21:41.489857  Epoch 4 : Average Loss 1.52679937\n",
      "2021-05-09 21:22:36.203358  Epoch 5 : Average Loss 1.36507149\n",
      "2021-05-09 21:23:28.370749  Epoch 6 : Average Loss 1.24796122\n",
      "2021-05-09 21:24:15.371192  Epoch 7 : Average Loss 1.16253832\n",
      "2021-05-09 21:25:05.764308  Epoch 8 : Average Loss 1.08544207\n",
      "2021-05-09 21:25:59.099116  Epoch 9 : Average Loss 1.01944638\n",
      "2021-05-09 21:26:49.511678  Epoch 10 : Average Loss 0.95826157\n",
      "2021-05-09 21:27:47.955539  Epoch 11 : Average Loss 0.90991461\n",
      "2021-05-09 21:28:43.741825  Epoch 12 : Average Loss 0.87378633\n",
      "2021-05-09 21:29:34.612782  Epoch 13 : Average Loss 0.81420096\n",
      "2021-05-09 21:30:23.286785  Epoch 14 : Average Loss 0.78154495\n",
      "2021-05-09 21:31:20.256326  Epoch 15 : Average Loss 0.74021978\n",
      "2021-05-09 21:32:15.912729  Epoch 16 : Average Loss 0.70331487\n",
      "2021-05-09 21:33:10.604470  Epoch 17 : Average Loss 0.66418291\n",
      "2021-05-09 21:34:07.035049  Epoch 18 : Average Loss 0.64434204\n",
      "2021-05-09 21:34:59.123472  Epoch 19 : Average Loss 0.61464214\n",
      "2021-05-09 21:35:47.587298  Epoch 20 : Average Loss 0.59087174\n",
      "2021-05-09 21:36:42.270038  Epoch 21 : Average Loss 0.56973609\n",
      "2021-05-09 21:37:36.801624  Epoch 22 : Average Loss 0.52873606\n",
      "2021-05-09 21:38:24.759596  Epoch 23 : Average Loss 0.51980866\n",
      "2021-05-09 21:39:19.557274  Epoch 24 : Average Loss 0.49381067\n",
      "2021-05-09 21:40:19.980754  Epoch 25 : Average Loss 0.47157164\n",
      "2021-05-09 21:41:09.631609  Epoch 26 : Average Loss 0.44642806\n",
      "2021-05-09 21:41:58.394006  Epoch 27 : Average Loss 0.42080462\n",
      "2021-05-09 21:42:51.617045  Epoch 28 : Average Loss 0.40266685\n",
      "2021-05-09 21:43:44.970316  Epoch 29 : Average Loss 0.38921755\n",
      "2021-05-09 21:44:37.004176  Epoch 30 : Average Loss 0.36655812\n",
      "Finished Training\n",
      "Training accuracy: 95.98 %\n",
      "Testing accuracy: 87.18 % (4359 / 5000)\n",
      "Testing accuracy (each class): \n",
      "0: 91.4%;   1: 84.6%;   2: 89.4%;   3: 77.2%;   4: 93.6%;   5: 85.2%;   \n",
      "6: 87.0%;   7: 93.0%;   8: 83.6%;   9: 86.8%;   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for opt in ('1e-4_expo','1e-4_step'):\n",
    "    model_ft = Net(net_param)\n",
    "    model_ft = model_ft.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    learning_rate, decay_strategy = optimizer_param_set[opt]\n",
    "    optimizer_ft = optim.Adam(model_ft.parameters(), lr=learning_rate)\n",
    "    if decay_strategy=='expo':\n",
    "        lr_scheduler_ft = lr_scheduler.ExponentialLR(optimizer_ft, gamma=0.2)\n",
    "    elif decay_strategy=='step':\n",
    "        lr_scheduler_ft = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.2)\n",
    "    elif decay_strategy=='mult':\n",
    "        lr_scheduler_ft = lr_scheduler.MultiStepLR(optimizer_ft, milestones=[10,25,30], gamma=0.2)\n",
    "    else:\n",
    "        print(\"ERROR 2\")\n",
    "            \n",
    "    print(\"optimizer parameter set: \", opt)\n",
    "    print(datetime.datetime.now())\n",
    "    epo = epoch\n",
    "    train_test(model_ft, criterion, optimizer_ft, lr_scheduler_ft, num_epochs=epo)\n",
    "        \n",
    "    loss_col.append(model_ft.loss_)\n",
    "    PATH = \"./cnn_chosen_\"+opt+\"_.pth\"\n",
    "    paths.append(PATH)\n",
    "    torch.save({'epoch': epoch,\n",
    "                'model_state_dict': model_ft.state_dict(),\n",
    "                'optimizer_state_dict': optimizer_ft.state_dict()\n",
    "               }, PATH)\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer parameter set:  1e-4_expo\n",
      "2021-05-09 22:29:00.688938\n",
      "CONV1 torch.Size([4, 16, 28, 28]) || CONV2 torch.Size([4, 32, 28, 28]) || POOL1 torch.Size([4, 32, 14, 14])\n",
      "CONV3 torch.Size([4, 32, 12, 12]) || CONV4 torch.Size([4, 16, 12, 12]) || POOL2 torch.Size([4, 16, 6, 6])\n",
      "FC1 torch.Size([4, 120]) || FC2 torch.Size([4, 60]) || FC3 torch.Size([4, 10])\n",
      "2021-05-09 22:29:48.142142  Epoch 1 : Average Loss 3.79017468\n",
      "2021-05-09 22:30:36.748259  Epoch 2 : Average Loss 2.24843753\n",
      "2021-05-09 22:31:34.084822  Epoch 3 : Average Loss 1.83018891\n",
      "2021-05-09 22:32:28.511608  Epoch 4 : Average Loss 1.58050202\n",
      "2021-05-09 22:33:18.313859  Epoch 5 : Average Loss 1.39712898\n",
      "2021-05-09 22:34:17.373930  Epoch 6 : Average Loss 1.26700837\n",
      "2021-05-09 22:35:11.916874  Epoch 7 : Average Loss 1.17886284\n",
      "2021-05-09 22:35:58.239016  Epoch 8 : Average Loss 1.09539515\n",
      "2021-05-09 22:36:48.165340  Epoch 9 : Average Loss 1.02682403\n",
      "2021-05-09 22:37:42.452587  Epoch 10 : Average Loss 0.97644355\n",
      "2021-05-09 22:38:31.151701  Epoch 11 : Average Loss 0.92005606\n",
      "2021-05-09 22:39:19.560079  Epoch 12 : Average Loss 0.88230604\n",
      "2021-05-09 22:40:12.772398  Epoch 13 : Average Loss 0.83776062\n",
      "2021-05-09 22:41:06.660887  Epoch 14 : Average Loss 0.80775269\n",
      "2021-05-09 22:41:55.011779  Epoch 15 : Average Loss 0.77344304\n",
      "2021-05-09 22:42:49.316067  Epoch 16 : Average Loss 0.74338466\n",
      "2021-05-09 22:43:42.348604  Epoch 17 : Average Loss 0.71210221\n",
      "2021-05-09 22:44:30.217151  Epoch 18 : Average Loss 0.68008259\n",
      "2021-05-09 22:45:20.524484  Epoch 19 : Average Loss 0.65763587\n",
      "2021-05-09 22:46:15.611903  Epoch 20 : Average Loss 0.62450306\n",
      "2021-05-09 22:47:04.993339  Epoch 21 : Average Loss 0.60427882\n",
      "2021-05-09 22:47:53.353279  Epoch 22 : Average Loss 0.57537535\n",
      "2021-05-09 22:48:47.747465  Epoch 23 : Average Loss 0.55792604\n",
      "2021-05-09 22:49:39.306568  Epoch 24 : Average Loss 0.52761708\n",
      "2021-05-09 22:50:25.525676  Epoch 25 : Average Loss 0.50624978\n",
      "2021-05-09 22:51:14.915248  Epoch 26 : Average Loss 0.49478875\n",
      "2021-05-09 22:52:08.960689  Epoch 27 : Average Loss 0.46998058\n",
      "2021-05-09 22:53:00.294534  Epoch 28 : Average Loss 0.45542637\n",
      "2021-05-09 22:53:47.360525  Epoch 29 : Average Loss 0.42534684\n",
      "2021-05-09 22:54:38.286640  Epoch 30 : Average Loss 0.40753887\n",
      "Finished Training\n",
      "Training accuracy: 95.98 %\n",
      "Testing accuracy: 87.64 % (4382 / 5000)\n",
      "Testing accuracy (each class): \n",
      "0: 90.6%;   1: 88.2%;   2: 87.2%;   3: 81.4%;   4: 91.6%;   5: 85.0%;   \n",
      "6: 85.0%;   7: 90.4%;   8: 86.6%;   9: 90.4%;   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt = '1e-4_expo'\n",
    "model_ft = Net(net_param)\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate, decay_strategy = optimizer_param_set[opt]\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=learning_rate)\n",
    "if decay_strategy=='expo':\n",
    "    lr_scheduler_ft = lr_scheduler.ExponentialLR(optimizer_ft, gamma=0.2)\n",
    "elif decay_strategy=='step':\n",
    "    lr_scheduler_ft = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.2)\n",
    "# elif decay_strategy=='lamb':\n",
    "    # lanbda1 = lambda epoch: 0.0001**epoch\n",
    "    # lr_scheduler_ft = lr_scheduler.LambdaLR(optimizer_ft, lr_lambda=lanbda1, last_epoch=-1)\n",
    "elif decay_strategy=='mult':\n",
    "    lr_scheduler_ft = lr_scheduler.MultiStepLR(optimizer_ft, milestones=[10,25,30], gamma=0.2)\n",
    "else:\n",
    "    print(\"ERROR 2\")\n",
    "        \n",
    "print(\"optimizer parameter set: \", opt)\n",
    "print(datetime.datetime.now())\n",
    "epo = epoch\n",
    "train_test(model_ft, criterion, optimizer_ft, lr_scheduler_ft, num_epochs=epo)\n",
    "    \n",
    "PATH = \"./final_model_.pth\"\n",
    "torch.save({'epoch': epoch,\n",
    "            'model_state_dict': model_ft.state_dict(),\n",
    "            'optimizer_state_dict': optimizer_ft.state_dict()\n",
    "           }, PATH)\n",
    "        \n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
