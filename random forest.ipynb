{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode(object):\n",
    "    def __init__(self, X, y, childs=[], info=None, isLeaf=True, split_feature=None, split_value=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.isLeaf = isLeaf\n",
    "        self.split_feature = split_feature\n",
    "        self.split_value = split_value\n",
    "        self.childs = childs\n",
    "        self.info = info\n",
    "        self.classes = np.unique(y)\n",
    "        counter=[]\n",
    "        for c in self.classes:\n",
    "            counter.append(np.sum(y==c))\n",
    "        self.class_ = self.classes[np.argmax(counter)]\n",
    "    def predict_single(self, X):\n",
    "        if self.isLeaf:\n",
    "            return self.class_\n",
    "        else:\n",
    "            if ((type(self.split_value) == int) | (type(self.split_value) == float)):\n",
    "                if (X[self.split_feature] >= self.split_value):\n",
    "                    return self.childs[0].predict_single(X)\n",
    "                else:\n",
    "                    return self.childs[1].predict_single(X)\n",
    "            else:\n",
    "                if (X[self.split_feature] == self.split_value):\n",
    "                    return self.childs[0].predict_single(X)\n",
    "                else:\n",
    "                    return self.childs[1].predict_single(X)\n",
    "    def predict(self, X):\n",
    "        if len(X.shape) > 0:\n",
    "            y_temp = []\n",
    "            for i in range(X.shape[0]):\n",
    "                y_temp.append(self.predict_single(X[i]))\n",
    "            return np.array(y_temp)\n",
    "        else:\n",
    "            return self.predict_single(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class DecisionTree(object):\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1, impurity_mode='gini', max_depth=5, min_gain=0.0):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "        self.max_depth = max_depth\n",
    "        self.min_gain = min_gain\n",
    "        self.impurity_mode = impurity_mode\n",
    "        # self.gini_max, self.entropy_max, self.classification_error_max = 0.5, 1.0, 0.5\n",
    "        \n",
    "    def impurity(self, y):\n",
    "        if self.impurity_mode == 'gini':\n",
    "            return self.gini(y)\n",
    "        elif self.impurity_mode == 'entropy':\n",
    "            return self.entropy(y)\n",
    "        else:\n",
    "            return self.classification_error(y)\n",
    "        \n",
    "    def gini(self, t):  # gini impuruty, t is the set of labels\n",
    "        tags = np.unique(t)\n",
    "        ig = 1\n",
    "        for tag in tags:\n",
    "            prob = np.sum(t==tag)/len(t)\n",
    "            ig -= prob**(2)\n",
    "        return ig \n",
    "    \n",
    "    def entropy(self, t):\n",
    "        tags = np.unique(t)\n",
    "        en = 0\n",
    "        for tag in tags:\n",
    "            prob = np.sum(t==tag)/len(t)\n",
    "            en -= prob*np.log2(prob)\n",
    "        return en        \n",
    "    \n",
    "    def classification_error(self, t):\n",
    "        tags = np.unique(t)\n",
    "        prob = []\n",
    "        for tag in tags:\n",
    "            prob.append(np.sum(t==tag)/len(t))\n",
    "        return 1-max(prob)\n",
    "    \n",
    "    def split(self, X, y, feature, value):  # binary split\n",
    "        n_child = 2\n",
    "        cX, cy = [], []\n",
    "        childnode_X, childnode_y = [], []\n",
    "        for _ in range(n_child):\n",
    "            cX.append([])\n",
    "            cy.append([])\n",
    "        if ((type(value) == int) | (type(value) == float)):\n",
    "            for i in range(X.shape[0]):\n",
    "                if (X[i, feature] >= value):\n",
    "                    cX[0].append(X[i])\n",
    "                    cy[0].append(y[i])\n",
    "                else:\n",
    "                    cX[1].append(X[i])\n",
    "                    cy[1].append(y[i])\n",
    "        else:\n",
    "            for i in range(X.shape[0]):\n",
    "                if (X[i, feature] == value):\n",
    "                    cX[0].append(X[i])\n",
    "                    cy[0].append(y[i])\n",
    "                else:\n",
    "                    cX[1].append(X[i])\n",
    "                    cy[1].append(y[i])\n",
    "        for i in range(n_child):\n",
    "            childnode_X.append(np.array(cX[i]))\n",
    "            childnode_y.append(np.array(cy[i]))\n",
    "        return childnode_X, childnode_y\n",
    "    \n",
    "    def build_decision_tree(self, X, y, depth=0):\n",
    "        if depth==0:\n",
    "            self.root = self.build_decision_tree(X, y, depth=1)\n",
    "        else:\n",
    "            impurity_current = self.impurity(y)\n",
    "            gain_best, feature_best, value_best, child_best_X, child_best_y = 0.0, None, None, None, None\n",
    "        \n",
    "            n_features = X.shape[1]\n",
    "            for feature in range(n_features):\n",
    "                values_ = np.unique(X[:, feature])\n",
    "                for value in values_:\n",
    "                    childnode_X, childnode_y = self.split(X, y, feature, value)\n",
    "                    p = len(childnode_y[0])/len(y)\n",
    "                    info_gain = impurity_current - p * self.impurity(childnode_y[0]) - (1-p) * self.impurity(childnode_y[1])\n",
    "                    if info_gain > gain_best:\n",
    "                        gain_best, feature_best, value_best = info_gain, feature, value\n",
    "                        child_best_X, child_best_y = childnode_X, childnode_y\n",
    "        \n",
    "            if gain_best > self.min_gain:\n",
    "                info = (depth, impurity_current, (len(child_best_y[0]), len(child_best_y[1])))\n",
    "                isnotLeaf = (depth <= self.max_depth) & (len(child_best_y[0])>0) & (len(child_best_y[1])>0)\n",
    "                if isnotLeaf:\n",
    "                    childs = []\n",
    "                    for i in range(2):\n",
    "                        childs.append(self.build_decision_tree(child_best_X[i], child_best_y[i], depth+1))\n",
    "                    return TreeNode(X=X, y=y, childs=childs, info=info, isLeaf=False, split_feature=feature_best, split_value=value_best)\n",
    "                else:\n",
    "                    return TreeNode(X=X, y=y, info=info, isLeaf=True)\n",
    "            else:\n",
    "                return TreeNode(X=X, y=y, info=(depth, impurity_current, (-1, -1)), isLeaf=True)\n",
    "    def predict_single(self, X):\n",
    "        return self.root.predict_single(X)\n",
    "    def predict(self, X):\n",
    "        return self.root.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class RandomForest(object):\n",
    "    def __init__(self, n_estimation=100, feature_delete=1, sample_delete=0, random_state=1, max_depth=5):\n",
    "        self.n_estimation = n_estimation\n",
    "        self.feature_delete = feature_delete\n",
    "        self.sample_delete = sample_delete\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "        self.max_depth = max_depth\n",
    "    def sample(self, X, y, n_sample, n_feature):\n",
    "        X_temp = []\n",
    "        y_temp = []\n",
    "        #rgen = np.random.RandomState(self.random_state)\n",
    "        #nx = rgen.uniform()\n",
    "        nx = np.random.choice(X.shape[0], n_sample)\n",
    "        nf = np.random.choice(X.shape[1], n_feature, replace=False)\n",
    "        for i in range(n_sample):\n",
    "            xi_temp = []\n",
    "            for j in range(n_feature):\n",
    "                xi_temp.append(X[nx[i]][nf[j]])\n",
    "            X_temp.append(np.array(xi_temp))\n",
    "            y_temp.append(y[nx[i]])\n",
    "        return np.array(X_temp), np.array(y_temp)\n",
    "    def fit(self, X, y):\n",
    "        self.n_sample = X.shape[0]-self.sample_delete\n",
    "        self.n_feature = X.shape[1]-self.feature_delete\n",
    "        print(self.n_sample, self.n_feature)\n",
    "        if (self.n_sample <= 0) | (self.n_feature<0):\n",
    "            print(\"illegal setting\")\n",
    "            return\n",
    "        for _ in range(self.n_estimation):\n",
    "            tree = DecisionTree(max_depth=self.max_depth)\n",
    "            X_temp, y_temp = self.sample(X=X, y=y, n_sample=self.n_sample, n_feature=self.n_feature)\n",
    "            # print(X_temp, y_temp)\n",
    "            tree.build_decision_tree(X_temp, y_temp)\n",
    "            self.trees.append(tree)\n",
    "    def predict_single(self, X):\n",
    "        y_pred = []\n",
    "        for tree in self.trees:\n",
    "            y_pred.append(tree.predict_single(X))\n",
    "        classes = np.unique(y_pred)\n",
    "        counter=[]\n",
    "        for c in classes:\n",
    "            counter.append(np.sum(y_pred==c))\n",
    "        return classes[np.argmax(counter)]\n",
    "    def predict(self, X):\n",
    "        if len(X.shape) > 0:\n",
    "            y_temp = []\n",
    "            for i in range(X.shape[0]):\n",
    "                y_temp.append(self.predict_single(X[i]))\n",
    "            # print(y_temp)\n",
    "            return np.array(y_temp)\n",
    "        else:\n",
    "            return self.predict_single(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd  \n",
    "df_trainX = pd.read_csv(\"/home/jiarui/Documents/3314/COMP3314_a1/dataset_files/iris_X_train.csv\", header=0, error_bad_lines=False)\n",
    "df_trainy = pd.read_csv(\"/home/jiarui/Documents/3314/COMP3314_a1/dataset_files/iris_y_train.csv\", header=0, error_bad_lines=False)\n",
    "df_testX = pd.read_csv(\"/home/jiarui/Documents/3314/COMP3314_a1/dataset_files/iris_X_test.csv\", header=0, error_bad_lines=False)\n",
    "df_testy = pd.read_csv(\"/home/jiarui/Documents/3314/COMP3314_a1/dataset_files/iris_y_test.csv\", header=0, error_bad_lines=False)\n",
    "X_train = df_trainX.iloc[:].values\n",
    "y_train = df_trainy.iloc[:, 0].values \n",
    "X_test = df_testX.iloc[:].values\n",
    "y_test = df_testy.iloc[:, 0].values\n",
    "\n",
    "markers = ('o', 'x', 's', '^', 'v')\n",
    "colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "labels = np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 3\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForest(n_estimation=1000, sample_delete=20, max_depth=6)\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "0.66 0.68\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "print(y_pred)\n",
    "test_error=(y_test!=y_pred).sum()\n",
    "y_pred = rf.predict(X_train)\n",
    "train_error=(y_train!=y_pred).sum()\n",
    "print(train_error/len(y_train), test_error/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_depth = []\n",
    "train_error = []\n",
    "test_error = []\n",
    "for i in range(16):\n",
    "    max_depth.append(1+i)\n",
    "    dt = DecisionTree(max_depth=max_depth[i])\n",
    "    dt.build_decision_tree(X_train, y_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    test_error.append((y_test!=y_pred).sum()/len(y_test)*100)\n",
    "    y_pred = dt.predict(X_train)\n",
    "    train_error.append((y_train!=y_pred).sum()/len(y_train)*100)\n",
    "\n",
    "plt.title(\"Random Forest\")\n",
    "plt.xlabel('maximum depth')\n",
    "plt.ylabel('error percentage')\n",
    "plt.plot(max_depth, test_error, marker='o', color='blue', label='test sample')\n",
    "plt.plot(max_depth, train_error, marker='x', color='red', label='train sample')\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()  # auto adjust the layout of whole picture\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
