

self.params = {'conv':[(), 
                               (3, 12, 5, 1, 0), 
                               (12, 36, 5, 1, 0)], # in_channels, out_channels, kernel_size, stride, padding
                       'pool':[(), 
                               (2, 2, 0),
                               (2, 2, 0)], # kernel_size, stride, padding
                       'fc':[(), 
                             (36*4*4, 120),
                             (120, 90), 
                             (90, 10)], # in_channels, out_channels
                      }
        
        self.conv1 = nn.Conv2d(*self.params['conv'][1])
        self.conv2 = nn.Conv2d(*self.params['conv'][2])
        
        self.pool1 = nn.MaxPool2d(*self.params['pool'][1])
        self.pool2 = nn.MaxPool2d(*self.params['pool'][2])
        
        self.fc1 = nn.Linear(*self.params['fc'][1])
        self.fc2 = nn.Linear(*self.params['fc'][2])
        self.fc3 = nn.Linear(*self.params['fc'][3])

2021-05-07 16:37:38.304215
epoch range:  1  to  5
CONV1 torch.Size([4, 12, 24, 24])
POOL1 torch.Size([4, 12, 12, 12])
CONV2 torch.Size([4, 36, 8, 8])
POOL2 torch.Size([4, 36, 4, 4])
FC1 torch.Size([4, 120])
FC2 torch.Size([4, 90])
FC3 torch.Size([4, 10])
2021-05-07 16:38:21.256870  Epoch 1 : Average Loss [2.1697646479010584, 1.4187639001458883, 1.1694475145675243]
2021-05-07 16:39:04.533745  Epoch 2 : Average Loss [0.9498343505328521, 0.9019007390867919, 0.8345316221409012]
2021-05-07 16:39:47.572063  Epoch 3 : Average Loss [0.7832544219074771, 0.748257465757546, 0.7235615325619583]
2021-05-07 16:40:33.797642  Epoch 4 : Average Loss [0.6842090065009543, 0.6608003924770747, 0.6712131032443139]
2021-05-07 16:41:18.623002  Epoch 5 : Average Loss [0.6086635890323814, 0.6306895254947158, 0.6085658124600304]
Finished Training
Training accuracy: 83 %
Testing accuracy: 80 %
Testing accuracy (each class): 
0: 84.4%;   1: 85.2%;   2: 82.2%;   3: 62.2%;   4: 90.8%;   5: 76.6%;   6: 78.2%;   7: 85.0%;   8: 77.8%;   9: 85.8%;   
2021-05-07 16:41:50.557581
epoch range:  6  to  10
2021-05-07 16:42:36.171037  Epoch 1 : Average Loss [0.5758213140422304, 0.5592337534239632, 0.5678163515266206]
2021-05-07 16:43:19.062586  Epoch 2 : Average Loss [0.5302258551147534, 0.5251520678091328, 0.539629439530836]
2021-05-07 16:44:02.768301  Epoch 3 : Average Loss [0.466360556404863, 0.5146413398111399, 0.5195738229487324]
2021-05-07 16:44:47.653561  Epoch 4 : Average Loss [0.4684601071547149, 0.4626834295654553, 0.4693734992832906]
2021-05-07 16:45:32.414461  Epoch 5 : Average Loss [0.4478211000367592, 0.44831783146440285, 0.4489816662927842]
Finished Training
Training accuracy: 87 %
Testing accuracy: 83 %
Testing accuracy (each class): 
0: 83.6%;   1: 88.2%;   2: 86.4%;   3: 77.0%;   4: 86.6%;   5: 80.0%;   6: 80.2%;   7: 90.0%;   8: 79.4%;   9: 87.8%;   
2021-05-07 16:46:03.501018
epoch range:  11  to  15
2021-05-07 16:46:50.186675  Epoch 1 : Average Loss [0.4215336232278496, 0.4248253271738431, 0.42431890928662325]
2021-05-07 16:47:35.432856  Epoch 2 : Average Loss [0.3830337310163369, 0.4089856769173621, 0.4147616113155782]
2021-05-07 16:48:25.270667  Epoch 3 : Average Loss [0.3872717271605852, 0.38071277964346156, 0.39063158788397234]
2021-05-07 16:49:15.962864  Epoch 4 : Average Loss [0.37934354527869163, 0.370959384032029, 0.3687803245810155]
2021-05-07 16:50:08.049168  Epoch 5 : Average Loss [0.36357739355761626, 0.3431833060975186, 0.3715965242988747]
Finished Training
Training accuracy: 89 %
Testing accuracy: 84 %
Testing accuracy (each class): 
0: 87.6%;   1: 89.0%;   2: 86.6%;   3: 72.4%;   4: 91.8%;   5: 87.2%;   6: 79.8%;   7: 90.0%;   8: 78.4%;   9: 86.6%;   
2021-05-07 16:50:40.632685
epoch range:  16  to  20
2021-05-07 16:51:28.652117  Epoch 1 : Average Loss [0.3421210554086292, 0.3471879129979793, 0.346647598462805]
2021-05-07 16:52:20.884486  Epoch 2 : Average Loss [0.31107052907974686, 0.3281729027932081, 0.3330757915337886]
2021-05-07 16:53:07.674848  Epoch 3 : Average Loss [0.31428100495739275, 0.315569723839053, 0.3193496690075615]
2021-05-07 16:53:57.920072  Epoch 4 : Average Loss [0.2950882508646, 0.29868973005820953, 0.30158825476568485]
2021-05-07 16:54:48.151402  Epoch 5 : Average Loss [0.28754521174445496, 0.2903587703375174, 0.2884582898568269]
Finished Training
Training accuracy: 92 %
Testing accuracy: 86 %
Testing accuracy (each class): 
0: 88.2%;   1: 87.6%;   2: 86.2%;   3: 80.6%;   4: 88.2%;   5: 86.2%;   6: 82.6%;   7: 90.6%;   8: 84.8%;   9: 86.0%;   
2021-05-07 16:55:21.553241
epoch range:  21  to  25
2021-05-07 16:56:09.932441  Epoch 1 : Average Loss [0.26124674596576053, 0.2765286000835911, 0.28124759030755103]
2021-05-07 16:57:06.799192  Epoch 2 : Average Loss [0.25262275893165254, 0.26302614843011135, 0.27190438008877776]
2021-05-07 16:57:58.887696  Epoch 3 : Average Loss [0.25444526311859045, 0.26118987226289436, 0.24475920500041834]
2021-05-07 16:58:48.408951  Epoch 4 : Average Loss [0.2439302240189071, 0.2511451678174277, 0.2601638498754873]
2021-05-07 16:59:34.561197  Epoch 5 : Average Loss [0.22196657354024246, 0.23856363265957833, 0.24482541932814791]
Finished Training
Training accuracy: 93 %
Testing accuracy: 85 %
Testing accuracy (each class): 
0: 86.4%;   1: 85.6%;   2: 86.2%;   3: 83.8%;   4: 90.0%;   5: 83.0%;   6: 80.2%;   7: 92.6%;   8: 85.0%;   9: 85.6%;   
2021-05-07 17:00:05.354877
epoch range:  26  to  30
2021-05-07 17:00:47.004914  Epoch 1 : Average Loss [0.23848219718358796, 0.2159409795830655, 0.22508164951149068]
2021-05-07 17:01:26.673512  Epoch 2 : Average Loss [0.2197478305118118, 0.2248928733031302, 0.2274391269242442]
2021-05-07 17:02:06.443942  Epoch 3 : Average Loss [0.21041834233705478, 0.2020515637737517, 0.22596847153563754]
2021-05-07 17:02:47.462956  Epoch 4 : Average Loss [0.19026188069016034, 0.2054312151889093, 0.20981415762956043]
2021-05-07 17:03:27.254298  Epoch 5 : Average Loss [0.17560136567605633, 0.21433034557646008, 0.20309274131743674]
Finished Training
Training accuracy: 95 %
Testing accuracy: 86 %
Testing accuracy (each class): 
0: 88.4%;   1: 85.8%;   2: 88.8%;   3: 83.2%;   4: 89.8%;   5: 81.6%;   6: 82.8%;   7: 91.8%;   8: 85.6%;   9: 82.8%;   

1

â€‹


