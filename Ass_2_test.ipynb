{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, transforms, utils\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    "\n",
    "net_param_set = [{'conv':[(),\n",
    "                          (3, 16, 5, 1, 1), \n",
    "                          (16, 32, 3, 1, 1),\n",
    "                          (32, 32, 3, 1, 0),\n",
    "                          (32, 16, 3, 1, 1)], # in_channels, out_channels, kernel_size, stride, padding\n",
    "              'pool':[(), \n",
    "                      (2, 2, 0),\n",
    "                      (2, 2, 0)], # kernel_size, stride, padding\n",
    "              'fc':[(), \n",
    "                    (16*6*6, 120),\n",
    "                    (120, 90), \n",
    "                    (90, 10)] # in_channels, out_channels\n",
    "             },\n",
    "             {'conv':[(), \n",
    "                      (3, 32, 5, 1, 1), \n",
    "                      (32, 32, 3, 1, 0),\n",
    "                      (32, 16, 3, 1, 1)], # in_channels, out_channels, kernel_size, stride, padding\n",
    "              'pool':[(), \n",
    "                      (2, 2, 0),\n",
    "                      (2, 2, 0)], # kernel_size, stride, padding\n",
    "              'fc':[(), \n",
    "                    (16*6*6, 120),\n",
    "                    (120, 90), \n",
    "                    (90, 10)] # in_channels, out_channels\n",
    "             },\n",
    "             {'conv':[(), \n",
    "                      (3, 32, 5, 1, 1), \n",
    "                      (32, 16, 3, 1, 0)], # in_channels, out_channels, kernel_size, stride, padding\n",
    "              'pool':[(), \n",
    "                      (2, 2, 0),\n",
    "                      (2, 2, 0)], # kernel_size, stride, padding\n",
    "              'fc':[(), \n",
    "                    (16*6*6, 120),\n",
    "                    (120, 90), \n",
    "                    (90, 10)] # in_channels, out_channels\n",
    "             }]\n",
    "             \n",
    "epoch_max = 30\n",
    "\n",
    "optimizer_param_set = [(1e-4, 'expo'),\n",
    "                       (5e-4, 'expo'),\n",
    "                       (1e-5, 'step'), \n",
    "                       (5e-5, 'step'), \n",
    "                       (1e-4, 'step'), \n",
    "                       (5e-4, 'step'),\n",
    "                       (1e-3, 'step')] # learning rate, decay strategy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    \n",
    "    # overall training correct rate\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloaders['train'], 0):\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Training accuracy: %d %%' % (100 * correct / total))\n",
    "    \n",
    "    # overall testing correct rate\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloaders['test'], 0):\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Testing accuracy: %d %%' % (100 * correct / total))\n",
    "    \n",
    "    # count testing predictions for each class\n",
    "    correct_pred = {classname: 0 for classname in class_names}\n",
    "    total_pred = {classname: 0 for classname in class_names}\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloaders['test'], 0):\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction:\n",
    "                    correct_pred[class_names[label]] += 1\n",
    "                total_pred[class_names[label]] += 1\n",
    "\n",
    "    # print accuracy for each class\n",
    "    print(\"Testing accuracy (each class): \")\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(\"{:1s}: {:.1f}%;  \".format(classname, accuracy), end=' ')\n",
    "        if classname == \"5\":\n",
    "            print()\n",
    "    print()\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def train_test(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    \n",
    "    for epoch in range(num_epochs):  \n",
    "\n",
    "        running_loss = 0.0\n",
    "        loss_record=[]\n",
    "        for i, data in enumerate(dataloaders['train'], 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                loss_record.append(round(running_loss / 2000, 4))\n",
    "                # print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "                \n",
    "        print(datetime.datetime.now(), ' Epoch', (epoch + 1), ': Average Loss', loss_record)\n",
    "\n",
    "    print('Finished Training')\n",
    "    \n",
    "    test(model)\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Data transformer\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((32,32)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((32,32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Dataset initialization\n",
    "data_dir = 'data' \n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'test']} # Read train and test sets, respectively.\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=0) for x in ['train', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Set device to \"cpu\" if you have no gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Input - 1x32x32\n",
    "    Output - 10\n",
    "    CONV1->CONV2->POOL1->CONV3->CONV4->POOL2->FC1->FC2->FC3\n",
    "    \"\"\"\n",
    "    def __init__(self, params):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #Initialize layers\n",
    "        self.params = params\n",
    "        self.n_layers = len(params['conv'])+len(params['pool'])+len(params['fc'])-3\n",
    "        self.printed = False\n",
    "        \n",
    "        if self.n_layers == 9:\n",
    "            self.conv1 = nn.Conv2d(*self.params['conv'][1])\n",
    "            self.conv2 = nn.Conv2d(*self.params['conv'][2])\n",
    "            self.conv3 = nn.Conv2d(*self.params['conv'][3])\n",
    "            self.conv4 = nn.Conv2d(*self.params['conv'][4])\n",
    "            \n",
    "            self.pool1 = nn.MaxPool2d(*self.params['pool'][1])\n",
    "            self.pool2 = nn.MaxPool2d(*self.params['pool'][2])\n",
    "            \n",
    "            self.fc1 = nn.Linear(*self.params['fc'][1])\n",
    "            self.fc2 = nn.Linear(*self.params['fc'][2])\n",
    "            self.fc3 = nn.Linear(*self.params['fc'][3])\n",
    "            \n",
    "        elif self.n_layers == 8:\n",
    "            self.conv1 = nn.Conv2d(*self.params['conv'][1])\n",
    "            self.conv2 = nn.Conv2d(*self.params['conv'][2])\n",
    "            self.conv3 = nn.Conv2d(*self.params['conv'][3])\n",
    "            \n",
    "            self.pool1 = nn.MaxPool2d(*self.params['pool'][1])\n",
    "            self.pool2 = nn.MaxPool2d(*self.params['pool'][2])\n",
    "            \n",
    "            self.fc1 = nn.Linear(*self.params['fc'][1])\n",
    "            self.fc2 = nn.Linear(*self.params['fc'][2])\n",
    "            self.fc3 = nn.Linear(*self.params['fc'][3])\n",
    "        \n",
    "        elif self.n_layers == 7:\n",
    "            self.conv1 = nn.Conv2d(*self.params['conv'][1])\n",
    "            self.conv2 = nn.Conv2d(*self.params['conv'][2])\n",
    "            \n",
    "            self.pool1 = nn.MaxPool2d(*self.params['pool'][1])\n",
    "            self.pool2 = nn.MaxPool2d(*self.params['pool'][2])\n",
    "            \n",
    "            self.fc1 = nn.Linear(*self.params['fc'][1])\n",
    "            self.fc2 = nn.Linear(*self.params['fc'][2])\n",
    "            self.fc3 = nn.Linear(*self.params['fc'][3])\n",
    "            \n",
    "\n",
    "    def forward(self, img):\n",
    "        # Implement forward pass\n",
    "        x = img\n",
    "        \n",
    "        if self.n_layers == 9:\n",
    "            x = F.relu(self.conv1(x))\n",
    "            if not self.printed: \n",
    "                print(\"CONV1\", x.size(), end=\" || \")\n",
    "            x = F.relu(self.conv2(x))\n",
    "            if not self.printed: \n",
    "                print(\"CONV2\", x.size(), end=\" || \")\n",
    "            x = self.pool1(x)\n",
    "            if not self.printed: \n",
    "                print(\"POOL1\", x.size())\n",
    "        \n",
    "            x = F.relu(self.conv3(x))\n",
    "            if not self.printed: \n",
    "                print(\"CONV3\", x.size(), end=\" || \")\n",
    "            x = F.relu(self.conv4(x))\n",
    "            if not self.printed: \n",
    "                print(\"CONV4\", x.size(), end=\" || \")\n",
    "            x = self.pool2(x)\n",
    "            if not self.printed: \n",
    "                print(\"POOL2\", x.size())\n",
    "        \n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            if not self.printed: \n",
    "                print(\"FC1\", x.size(), end=\" || \")\n",
    "            x = F.relu(self.fc2(x))\n",
    "            if not self.printed: \n",
    "                print(\"FC2\", x.size(), end=\" || \")\n",
    "            x = self.fc3(x)\n",
    "            if not self.printed: \n",
    "                print(\"FC3\", x.size())\n",
    "                \n",
    "        elif self.n_layers == 8:\n",
    "            x = F.relu(self.conv1(x))\n",
    "            if not self.printed: \n",
    "                print(\"CONV1\", x.size(), end=\" || \")\n",
    "            x = self.pool1(x)\n",
    "            if not self.printed: \n",
    "                print(\"POOL1\", x.size())\n",
    "        \n",
    "            x = F.relu(self.conv2(x))\n",
    "            if not self.printed: \n",
    "                print(\"CONV2\", x.size(), end=\" || \")\n",
    "            x = F.relu(self.conv3(x))\n",
    "            if not self.printed: \n",
    "                print(\"CONV3\", x.size(), end=\" || \")\n",
    "            x = self.pool2(x)\n",
    "            if not self.printed: \n",
    "                print(\"POOL2\", x.size())\n",
    "        \n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            if not self.printed: \n",
    "                print(\"FC1\", x.size(), end=\" || \")\n",
    "            x = F.relu(self.fc2(x))\n",
    "            if not self.printed: \n",
    "                print(\"FC2\", x.size(), end=\" || \")\n",
    "            x = self.fc3(x)\n",
    "            if not self.printed: \n",
    "                print(\"FC3\", x.size())\n",
    "        \n",
    "        elif self.n_layers == 7:\n",
    "            x = F.relu(self.conv1(x))\n",
    "            if not self.printed: \n",
    "                print(\"CONV1\", x.size(), end=\" || \")\n",
    "            x = self.pool1(x)\n",
    "            if not self.printed: \n",
    "                print(\"POOL1\", x.size())\n",
    "        \n",
    "            x = F.relu(self.conv2(x))\n",
    "            if not self.printed: \n",
    "                print(\"CONV2\", x.size(), end=\" || \")\n",
    "            x = self.pool2(x)\n",
    "            if not self.printed: \n",
    "                print(\"POOL2\", x.size())\n",
    "        \n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            if not self.printed: \n",
    "                print(\"FC1\", x.size(), end=\" || \")\n",
    "            x = F.relu(self.fc2(x))\n",
    "            if not self.printed: \n",
    "                print(\"FC2\", x.size(), end=\" || \")\n",
    "            x = self.fc3(x)\n",
    "            if not self.printed: \n",
    "                print(\"FC3\", x.size())\n",
    "        \n",
    "        self.printed = True\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 , 0\n",
      "2021-05-08 17:45:15.144096\n",
      "epoch range:  1  to  5\n",
      "CONV1 torch.Size([4, 16, 30, 30]) || CONV2 torch.Size([4, 32, 30, 30]) || POOL1 torch.Size([4, 32, 15, 15])\n",
      "CONV3 torch.Size([4, 32, 13, 13]) || CONV4 torch.Size([4, 16, 13, 13]) || POOL2 torch.Size([4, 16, 6, 6])\n",
      "FC1 torch.Size([4, 120]) || FC2 torch.Size([4, 90]) || FC3 torch.Size([4, 10])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-35e484a5ac4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mepo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch range: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepo\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" to \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mtrain_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./cnn\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-e21844ac5646>\u001b[0m in \u001b[0;36mtrain_test\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;31m# zero the parameter gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jiarui/snap/jupyter/common/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-612df9c383e1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CONV1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" || \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jiarui/snap/jupyter/common/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jiarui/snap/jupyter/common/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jiarui/snap/jupyter/common/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "paths = []\n",
    "for j in range(len(optimizer_param_set)):\n",
    "    for i in range(len(net_param_set)):\n",
    "        model_ft = Net(net_param_set[i])\n",
    "        model_ft = model_ft.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        learning_rate, decay_strategy = optimizer_param_set[j]\n",
    "        optimizer_ft = optim.Adam(model_ft.parameters(), lr=learning_rate)\n",
    "        if decay_strategy=='expo':\n",
    "            lr_scheduler = lr_scheduler.ExponentialLR(optimizer_ft, gamma=0.1)\n",
    "        elif decay_strategy=='step':\n",
    "            lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)\n",
    "        else:\n",
    "            print(\"EEOR 2\")\n",
    "        \n",
    "        print(i, \",\", j)\n",
    "        for n in range((epoch_max // 5)):\n",
    "            print(datetime.datetime.now())\n",
    "            epo = 5*n+5\n",
    "            print(\"epoch range: \", epo-4, \" to \", epo)\n",
    "            train_test(model_ft, criterion, optimizer_ft, lr_scheduler, num_epochs=5)\n",
    "        \n",
    "        PATH = \"./cnn\"+str(i)+\"_\"+str(j)+\"_.pth\"\n",
    "        paths.append(PATH)\n",
    "        torch.save({'epoch': epoch,\n",
    "                    'model_state_dict': model_ft.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer_ft.state_dict()\n",
    "                   }, PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
